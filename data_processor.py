import os
import orjson
import sqlite3
import json
import pandas as pd
import numpy as np
from datetime import datetime
import glob
from collections import defaultdict

class DataProcessor:
    def __init__(self, data_dir):
        self.data_dir = data_dir
        self.timeframes = ['7D', '14D', '30D', 'TOTAL']
        # DB íŒŒì¼ ê²½ë¡œ ì„¤ì •
        self.db_path = os.path.join(data_dir, "project_data.db")
        
        # 1. DB ì´ˆê¸°í™” (í…Œì´ë¸” ë° ì¸ë±ìŠ¤ ìƒì„±)
        self._init_db()
        
        # 2. ìµœì‹  íŒŒì¼ ì •ë³´ ë¡œë“œ (AttributeError í•´ê²° ì§€ì )
        self.latest_file = self._load_latest_file_info()

    def _init_db(self):
        """DB ì—°ê²° ë° í•„ìš”í•œ í…Œì´ë¸”/ì¸ë±ìŠ¤ ìƒì„±"""
        with sqlite3.connect(self.db_path, check_same_thread=False) as conn:
            cursor = conn.cursor()
            
            # WAL ëª¨ë“œ í™œì„±í™” (ì“°ê¸° ì¤‘ì—ë„ ì½ê¸° ê°€ëŠ¥)
            cursor.execute('PRAGMA journal_mode=WAL')
            cursor.execute('PRAGMA busy_timeout=30000')  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
            
            # ë©”ì¸ ë°ì´í„° í…Œì´ë¸” ìˆ˜ì •
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS snaps (
                    id TEXT,              -- ğŸš¨ 'id' ì»¬ëŸ¼ ì¶”ê°€
                    timeframe TEXT,
                    username TEXT,
                    displayName TEXT,
                    rank INTEGER,
                    cSnapsPercentRank INTEGER,
                    snapsPercent REAL,
                    cSnapsPercent REAL,
                    followers INTEGER,
                    smartFollowers INTEGER,
                    timestamp TEXT,
                    profileImageUrl TEXT
                )
            """)
            # íŒŒì¼ ë™ê¸°í™”ë¥¼ ìœ„í•œ ë©”íƒ€ë°ì´í„° í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS metadata (
                    key TEXT PRIMARY KEY,
                    value TEXT
                )
            """)
            # ê²€ìƒ‰ ë° ì¡°íšŒë¥¼ ìœ„í•œ ì¸ë±ìŠ¤ ìµœì í™”
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_user_tf ON snaps (username, timeframe)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_ts_tf ON snaps (timestamp, timeframe)")
            conn.commit()

    def _load_latest_file_info(self):
        """DB ë©”íƒ€ë°ì´í„° í…Œì´ë¸”ì—ì„œ ë§ˆì§€ë§‰ ë¡œë“œëœ íŒŒì¼ëª…ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        latest_info = {}
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                for tf in self.timeframes:
                    cursor.execute("SELECT value FROM metadata WHERE key = ?", (f"latest_file_{tf}",))
                    row = cursor.fetchone()
                    latest_info[tf] = row[0] if row else ""
        except:
            pass
        return latest_info

    def _save_latest_file_info(self, timeframe, filename):
        """ë§ˆì§€ë§‰ ë¡œë“œëœ íŒŒì¼ëª…ì„ DBì— ì €ì¥í•©ë‹ˆë‹¤."""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("INSERT OR REPLACE INTO metadata (key, value) VALUES (?, ?)", 
                          (f"latest_file_{timeframe}", filename))
            conn.commit()

    def load_data(self, files_to_load=None):
        """ì‹ ê·œ JSON íŒŒì¼ì„ DBì— ì¸ì„œíŠ¸í•˜ê³  êµ¬ë²„ì „ íŒŒì¼ì„ ì‚­ì œí•©ë‹ˆë‹¤."""
        if files_to_load is None:
            files_to_load = self.check_for_new_data()

        if not files_to_load:
            return False

        new_data_found = False
        with sqlite3.connect(self.db_path) as conn:
            for timeframe, files in files_to_load.items():
                if not files: continue
                
                all_records = []
                for file_path in files:
                    try:
                        filename = os.path.basename(file_path)
                        parts = filename.split('_')
                        ts_str = f"{parts[0]}_{parts[1]}"
                        timestamp = datetime.strptime(ts_str, '%Y%m%d_%H%M%S').strftime('%Y-%m-%d %H:%M:%S')
                        
                        with open(file_path, 'rb') as f:
                            raw_data = orjson.loads(f.read())
                        
                        if 'result' in raw_data and 'data' in raw_data['result']:
                            snaps = raw_data['result']['data']['json'].get('snaps', [])
                            for snap in snaps:
                                snap['timeframe'] = timeframe
                                snap['timestamp'] = timestamp
                                all_records.append(snap)
                            
                            # ìµœì‹  íŒŒì¼ ì •ë³´ ê°±ì‹ 
                            self.latest_file[timeframe] = filename
                            self._save_latest_file_info(timeframe, filename)
                            new_data_found = True
                    except Exception as e:
                        print(f"Error parsing {file_path}: {e}")

                if all_records:
                    df = pd.DataFrame(all_records)
                    
                    # smartFollowersDetails ì»¬ëŸ¼ ì œê±° (ìš©ëŸ‰ ì ˆì•½ì„ ìœ„í•´ ê°œìˆ˜ë§Œ ì €ì¥)
                    if 'smartFollowersDetails' in df.columns:
                        df = df.drop('smartFollowersDetails', axis=1)
                    
                    # ë³µí•© ê°ì²´(list, dict)ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜ (ì¶”ê°€ëœ ë¡œì§)
                    for col in df.columns:
                        if df[col].apply(lambda x: isinstance(x, (list, dict))).any():
                            df[col] = df[col].apply(lambda x: orjson.dumps(x).decode('utf-8') if x is not None else None)

                    # DB ìŠ¤í‚¤ë§ˆ ìë™ ì—…ë°ì´íŠ¸
                    cursor = conn.cursor()
                    cursor.execute("PRAGMA table_info(snaps)")
                    existing_columns = [info[1] for info in cursor.fetchall()]
                    for col in df.columns:
                        if col not in existing_columns:
                            cursor.execute(f"ALTER TABLE snaps ADD COLUMN {col} TEXT")
                    
                    df.to_sql('snaps', conn, if_exists='append', index=False)
                    print(f"[{timeframe}] DB Insert Complete.")

        # ğŸš¨ ë°ì´í„° ì‚½ì…ì´ ì™„ì „íˆ ëë‚œ í›„ íŒŒì¼ ì •ë¦¬ ì‹¤í–‰
        if new_data_found:
            self.cleanup_old_files()
            
        return new_data_found

    # data_processor.pyì˜ cleanup_old_files ë©”ì„œë“œ ìˆ˜ì •

    def cleanup_old_files(self):
        """DBì— ê¸°ë¡ëœ ìµœì‹  íŒŒì¼ë³´ë‹¤ 'ê³¼ê±°'ì˜ íŒŒì¼ë“¤ë§Œ ì‚­ì œí•©ë‹ˆë‹¤."""
        print(f"--- [{self.data_dir}] ì•ˆì „í•œ íŒŒì¼ ì •ë¦¬ ì‹œì‘ ---")
        for tf in self.timeframes:
            path = os.path.join(self.data_dir, tf)
            if not os.path.exists(path): continue
            
            # DBê°€ ê¸°ì–µí•˜ëŠ” ì´ íƒ€ì„í”„ë ˆì„ì˜ ìµœì‹  íŒŒì¼ëª… (ê¸°ì¤€ì )
            latest_filename = self.latest_file.get(tf, "")
            if not latest_filename: continue
            
            # í´ë” ë‚´ ëª¨ë“  json íŒŒì¼ ë¦¬ìŠ¤íŠ¸ì—…
            all_files = glob.glob(os.path.join(path, "*.json"))
            
            for f_path in all_files:
                f_name = os.path.basename(f_path)
                
                # ğŸš¨ [ìˆ˜ì •] != ëŒ€ì‹  < ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
                # 'ê¸°ì¤€ì´ ë˜ëŠ” ìµœì‹  íŒŒì¼'ë³´ë‹¤ ì´ë¦„(ì‹œê°„)ì´ ì‘ì€ íŒŒì¼ë§Œ ì‚­ì œí•©ë‹ˆë‹¤.
                if f_name < latest_filename:
                    try:
                        os.remove(f_path)
                        # print(f"Deleted old file: {f_name}")
                    except Exception as e:
                        print(f"Failed to delete {f_name}: {e}")
                
                # ë§Œì•½ f_name > latest_filename ì´ë¼ë©´? 
                # -> ë°©ê¸ˆ ë§‰ ë“¤ì–´ì˜¨ ë”°ëˆë”°ëˆí•œ ìƒˆ íŒŒì¼ì´ë¯€ë¡œ ì‚­ì œí•˜ì§€ ì•Šê³  ë‚¨ê²¨ë‘¡ë‹ˆë‹¤.
                # -> ë‹¤ìŒ ì£¼ê¸°(30ì´ˆ í›„)ì— load_dataê°€ ì´ë¥¼ ë°œê²¬í•˜ì—¬ ì²˜ë¦¬í•  ê²ƒì…ë‹ˆë‹¤.

    def check_for_new_data(self):
        """ìƒˆë¡œ ìƒì„±ëœ JSON íŒŒì¼ì´ ìˆëŠ”ì§€ ì²´í¬í•©ë‹ˆë‹¤."""
        new_files = defaultdict(list)
        any_new = False
        for tf in self.timeframes:
            path = os.path.join(self.data_dir, tf)
            if not os.path.exists(path): continue
            
            all_files = sorted(glob.glob(os.path.join(path, "*.json")))
            last_loaded = self.latest_file.get(tf, "")
            for f in all_files:
                if os.path.basename(f) > last_loaded:
                    new_files[tf].append(f)
                    any_new = True
        return new_files if any_new else {}

    # --- ë°ì´í„° ì¡°íšŒ í•¨ìˆ˜ë“¤ (main.pyì™€ í˜¸í™˜) ---

    def get_available_timestamps(self, timeframe='TOTAL'):
        query = "SELECT DISTINCT timestamp FROM snaps WHERE timeframe = ? ORDER BY timestamp ASC"
        with sqlite3.connect(self.db_path) as conn:
            df = pd.read_sql(query, conn, params=(timeframe,))
        return df['timestamp'].tolist()

    def get_leaderboard_at_timestamp(self, timestamp, timeframe='TOTAL'):
        query = """
            SELECT username, displayName, rank, cSnapsPercentRank, 
                   snapsPercent, cSnapsPercent, followers, 
                   profileImageUrl, timestamp, timeframe 
            FROM snaps WHERE timestamp = ? AND timeframe = ?
        """
        with sqlite3.connect(self.db_path) as conn:
            return pd.read_sql(query, conn, params=(timestamp, timeframe))

    def get_user_history(self, username, timeframe='TOTAL'):
        query = """
            SELECT displayName, timestamp , rank, cSnapsPercentRank, 
                   snapsPercent, cSnapsPercent
            FROM snaps WHERE username = ? AND timeframe = ? ORDER BY timestamp ASC
        """
        with sqlite3.connect(self.db_path) as conn:
            history = pd.read_sql(query, conn, params=(username, timeframe))
        if history.empty: return pd.DataFrame()
        history['timestamp'] = pd.to_datetime(history['timestamp'])
        if len(history) > 500:
            indices = np.linspace(0, len(history) - 1, 500).astype(int)
            history = history.iloc[indices]
        return history

    def get_all_usernames(self, timeframe='TOTAL'):
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT MAX(timestamp) FROM snaps WHERE timeframe = ?", (timeframe,))
            latest_ts = cursor.fetchone()[0]
            if not latest_ts: return []
            query = "SELECT username, displayName FROM snaps WHERE timestamp = ? AND timeframe = ?"
            return pd.read_sql(query, conn, params=(latest_ts, timeframe)).to_dict('records')
    
    def get_all_usernames_from_multiple_timeframes(self, timeframes=['7D', '14D', '30D', 'TOTAL']):
        """ì—¬ëŸ¬ timeframeì—ì„œ ì‚¬ìš©ìë¥¼ ê°€ì ¸ì™€ ì¤‘ë³µ ì œê±° í›„ ë°˜í™˜"""
        all_users = {}
        with sqlite3.connect(self.db_path) as conn:
            for tf in timeframes:
                cursor = conn.cursor()
                cursor.execute("SELECT MAX(timestamp) FROM snaps WHERE timeframe = ?", (tf,))
                latest_ts = cursor.fetchone()[0]
                if not latest_ts:
                    continue
                query = "SELECT username, displayName FROM snaps WHERE timestamp = ? AND timeframe = ?"
                users = pd.read_sql(query, conn, params=(latest_ts, tf)).to_dict('records')
                for user in users:
                    # usernameì„ í‚¤ë¡œ ì‚¬ìš©í•˜ì—¬ ì¤‘ë³µ ì œê±°
                    if user['username'] not in all_users:
                        all_users[user['username']] = user
        return list(all_users.values())

    def get_user_info_by_timeframe(self, username, timeframe='TOTAL'):
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT MAX(timestamp) FROM snaps WHERE timeframe = ?", (timeframe,))
            latest_ts = cursor.fetchone()[0]
            if not latest_ts: return self.get_user_info(username)
            query = """
                SELECT username, displayName, rank, cSnapsPercentRank, 
                       snapsPercent, cSnapsPercent, followers, smartFollowers, 
                       profileImageUrl
                FROM snaps WHERE username = ? AND timeframe = ? AND timestamp = ?
            """
            user_df = pd.read_sql(query, conn, params=(username, timeframe, latest_ts))
            if not user_df.empty: return user_df.iloc[0].to_dict()
        return self.get_user_info(username)

    def get_user_info(self, username):
        query = "SELECT username, displayName, profileImageUrl, followers, smartFollowers FROM snaps WHERE username = ? ORDER BY timestamp DESC LIMIT 1"
        with sqlite3.connect(self.db_path) as conn:
            df = pd.read_sql(query, conn, params=(username,))
            if not df.empty: return df.iloc[0].to_dict()
        return {'username': username, 'displayName': username}

    def get_user_analysis(self, username):
        return {tf: self.get_user_history(username, tf) for tf in self.timeframes}

    def compare_leaderboards(self, timestamp1, timestamp2, timeframe='TOTAL', metric='snapsPercent'):
        # 1. ì»¬ëŸ¼ ì„¤ì •
        if metric == 'snapsPercent':
            rank_col, ms_col, diff_col = 'rank', 'snapsPercent', 'mindshare_change'
        else:
            rank_col, ms_col, diff_col = 'cSnapsPercentRank', 'cSnapsPercent', 'c_mindshare_change'
            
        # 2. ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        df1 = self.get_leaderboard_at_timestamp(timestamp1, timeframe)
        df2 = self.get_leaderboard_at_timestamp(timestamp2, timeframe)
        if df1.empty and df2.empty: return pd.DataFrame()

        # 3. ë°ì´í„° ì „ì²˜ë¦¬ (ì´ë¦„ ë³€ê²½)
        df1 = df1[['username', 'displayName', rank_col, ms_col, 'profileImageUrl']].rename(columns={
            rank_col: 'prev_rank', ms_col: 'prev_mindshare', 'profileImageUrl': 'prev_profileImageUrl'
        })
        df2 = df2[['username', 'displayName', rank_col, ms_col, 'profileImageUrl']].rename(columns={
            rank_col: 'curr_rank', ms_col: 'curr_mindshare', 'profileImageUrl': 'curr_profileImageUrl'
        })
        
        # 4. ë³‘í•© ë° ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°
        compare_data = pd.merge(df1, df2, on='username', how='outer', suffixes=('_prev', '_curr'))
        compare_data['displayName'] = compare_data['displayName_curr'].combine_first(compare_data['displayName_prev']).fillna('')
        compare_data['profileImageUrl'] = compare_data['curr_profileImageUrl'].combine_first(compare_data['prev_profileImageUrl']).fillna('')
        
        # ì—¬ê¸°ì„œ 9999ì™€ 0ìœ¼ë¡œ ì±„ì›€
        compare_data.fillna({'prev_mindshare': 0, 'curr_mindshare': 0, 'prev_rank': 9999, 'curr_rank': 9999}, inplace=True)
        
        # 5. ë³€ë™í­ ê³„ì‚°
        compare_data['rank_change'] = compare_data['prev_rank'] - compare_data['curr_rank']
        compare_data[diff_col] = compare_data['curr_mindshare'] - compare_data['prev_mindshare']
        
        # --- [ìˆ˜ì •ëœ ë¶€ë¶„] ë³´ì • ë¡œì§ ì‹œì‘ ---
        
        # (1) ìˆœìœ„ ë³€ë™ ë³´ì •: 500ë“± ì´ìƒ ì°¨ì´ë‚˜ë©´(ì§„ì…/ì´íƒˆ) ìˆœìœ„ ë³€ë™ 0 ì²˜ë¦¬
        compare_data['rank_change'] = np.where(abs(compare_data['rank_change']) > 500, 0, compare_data['rank_change'])

        # (2) ë§ˆì¸ë“œì‰ì–´ ë³€ë™ ë³´ì •: ì´ì „ì´ë‚˜ í˜„ì¬ ìˆœìœ„ ì¤‘ í•˜ë‚˜ë¼ë„ 999(ìˆœìœ„ ë°–)ë©´ ë§ˆì¸ë“œì‰ì–´ ë³€ë™ 0 ì²˜ë¦¬
        compare_data[diff_col] = np.where(
            (compare_data['prev_rank'] == 9999) | (compare_data['curr_rank'] == 9999), 
            0, 
            compare_data[diff_col]
        )
        
        # --- [ìˆ˜ì •ëœ ë¶€ë¶„] ë³´ì • ë¡œì§ ë ---

        # 6. ê²°ê³¼ ì •ë¦¬
        result = compare_data[['username', 'displayName', 'profileImageUrl', 'prev_rank', 'curr_rank', 'rank_change', 
                              'prev_mindshare', 'curr_mindshare', diff_col]].copy()
        
        if metric == 'cSnapsPercent':
             result.rename(columns={'prev_mindshare': 'prev_c_mindshare', 'curr_mindshare': 'curr_c_mindshare'}, inplace=True)
        
        result.sort_values('rank_change', ascending=False, inplace=True)
        return result

    def get_all_users(self):
        return self.get_all_usernames('TOTAL')